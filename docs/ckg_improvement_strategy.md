# Дорожная карта по улучшению CKG: от структурного индекса к гибридной системе анализа кода

Этот документ описывает пошаговый план развития системы Code Knowledge Graph (CKG), основанный на экспертном анализе и лучших практиках индустрии. Цель — превратить текущую реализацию из простого индексатора символов в мощную гибридную систему, сочетающую структурный и семантический поиск.

## Основная идея: Гибридная модель

Мы объединяем два подхода:
1.  **CKG (Структурная база):** Остается ядром для точных, детерминированных запросов (поиск определений функций/классов).
2.  **Векторная база (Семантический поиск):** Добавляется для поиска по смысловому сходству, что позволяет находить похожие реализации, идиомы и примеры использования.

---

## Этап 1: Оптимизация фундамента (улучшение существующего CKG)

**Цель:** Устранить ключевой недостаток текущей системы — полную перестройку индекса при малейшем изменении. Сделать CKG более гранулярным и быстрым.

**Задачи:**

1.  **Переход от хеша всей кодовой базы к хешированию пофайлово.**
    -   **Что делаем:** Вместо одного `codebase_snapshot_hash` хранить в `storage_info.json` словарь вида `{ "file_path": "file_hash" }`.
    -   **Как:** При запуске сканировать директорию, сравнивать хеши каждого файла с сохраненными.
    -   **Результат:** Вместо полной перестройки базы мы будем удалять и заново индексировать только те файлы, которые изменились. Это драматически ускорит обновление для больших проектов.

2.  **Реализация `file watcher`'а (наблюдателя за файлами).**
    -   **Что делаем:** Вместо сканирования при каждом запросе, запустить фоновый процесс, который следит за изменениями файлов в реальном времени (используя системные API, например, `watchdog` в Python).
    -   **Как:** При обнаружении изменения файла (создание, удаление, модификация), `watcher` триггерит переиндексацию только этого конкретного файла.
    -   **Результат:** Индекс становится "живым" и почти мгновенно отражает изменения в коде.

3.  **Оптимизация запросов к SQLite.**
    -   **Что делаем:** Проверить и добавить необходимые индексы для таблиц `functions` и `classes` (например, по `name` и `file_path`). Использовать `PRAGMA journal_mode=WAL` для улучшения производительности при одновременной записи и чтении.
    -   **Результат:** Ускорение запросов к базе данных.

---

## Этап 2: Внедрение семантического поиска (Векторизация)

**Цель:** Добавить в систему "понимание" смысла кода, а не только его структуры.

**Задачи:**

1.  **Разработка AST-aware chunker'а (умного разделителя кода).**
    -   **Что делаем:** Создать компонент, который делит исходный код на семантически целостные куски. Не просто резать по 512 токенов, а делить на уровне функций, классов, методов.
    -   **Как:** Использовать `tree-sitter` для навигации по синтаксическому дереву и определения границ логических блоков.
    -   **Результат:** Качественные "чанки" кода, которые идеально подходят для векторизации, так как сохраняют семантический контекст.

2.  **Интеграция с моделью для создания эмбеддингов.**
    -   **Что делаем:** Настроить pipeline, который берет чанки из предыдущего шага и отправляет их в специализированную модель для получения векторов (эмбеддингов).
    -   **Как:** Выбрать модель, оптимизированную для кода (например, `voyage-code-2`, `unixcoder` или модели от OpenAI). Реализовать батчинг (отправку пачками) для экономии на API-вызовах и обработку ошибок/повторных попыток.
    -   **Результат:** Каждый смысловой кусок кода получает свое векторное представление.

3.  **Развертывание и наполнение векторной базы данных.**
    -   **Что делаем:** Выбрать и настроить векторную СУБД для хранения эмбеддингов.
    -   **Как:** Для локальной разработки подойдет `Qdrant` или `ChromaDB`. Для продакшена — `Pinecone`, `Milvus` или облачные решения. В базе хранить вектор и метаданные (ID чанка, путь к файлу, номера строк).
    -   **Результат:** Построенный и готовый к работе индекс для семантического поиска.

---

## Этап 3: Создание гибридной системы (Интеграция и маршрутизация)

**Цель:** Объединить два мира — структурный и семантический — в единый, умный инструмент.

**Задачи:**

1.  **Разработка маршрутизатора запросов (Query Router).**
    -   **Что делаем:** Создать компонент, который анализирует запрос пользователя (или LLM) и решает, куда его направить.
    -   **Как:**
        -   Если запрос — точный поиск символа (`"где определен MyClass?"`), он идет в **CKG (SQLite)**.
        -   Если запрос — семантический (`"найди похожие реализации"`, `"примеры аутентификации"`), он векторизуется и идет в **векторную базу**.
        -   Для смешанных запросов можно выполнять оба поиска и объединять результаты.
    -   **Результат:** Агент использует наиболее подходящий инструмент для каждой конкретной задачи, что повышает скорость и релевантность ответов.

2.  **Реализация инкрементальных обновлений для векторов.**
    -   **Что делаем:** Связать обновление векторов с пофайловым хешированием из Этапа 1.
    -   **Как:** Использовать хеш контента чанка. Если чанк с таким хешем уже векторизован, не делать этого повторно. Обновлять вектора только для новых или измененных чанков. Это можно реализовать с помощью Merkle-деревьев для максимальной эффективности.
    -   **Результат:** Значительная экономия вычислительных ресурсов и денег на API эмбеддингов.

---

## Этап 4: Эксплуатация и безопасность

**Цель:** Обеспечить стабильность, безопасность и управляемость системы.

**Задачи:**

1.  **Настройка мониторинга и логирования.**
    -   Отслеживать ключевые метрики: время ответа, количество запросов к CKG/векторной базе, стоимость API-вызовов.

2.  **Реализация политик хранения данных (Retention).**
    -   Автоматически удалять старые или неактуальные индексы (например, для удаленных веток Git).

3.  **Проработка модели безопасности и приватности.**
    -   Решить, где хранятся эмбеддинги и код. Для максимальной приватности можно реализовать модель, как у Cursor: на сервере хранятся только вектора и обфусцированные метаданные, а сам код никогда не покидает машину пользователя.
